#Setting directory

setwd("C:/Users/daily/Desktop/Repositories/Practical-Machine-Learning-in-R/Chapter 7")

#Loading necessary libraries and data set

library(tidyverse)
library(dplyr)

email <- read_csv(file = "C:/Users/daily/Desktop/Repositories/Practical-Machine-Learning-in-R/Chapter 7/Data/email.csv")

#View the data

head(email)

#Making the message_label variable into a factor

email <- email %>%
  mutate(message_label = as.factor(message_label))

#Find the count of the words used and group data by sum of count variable

email %>%
  gather(key = word, value = count, -message_index, -message_label) %>%
  group_by(word) %>%
  summarize(occurence = sum(count)) %>%
  arrange(desc(occurence)) %>%
  slice(1:10)

#Find the top 10 words for ham messages

email %>%
  filter(message_label == "ham") %>%
  gather(key = word, value = count, -message_index, -message_label) %>%
  group_by(word) %>%
  summarize(occurence = sum(count)) %>%
  arrange(desc(occurence)) %>%
  slice(1:10)

#Find the top 10 words for spam messages

email %>%
  filter(message_label == "spam") %>%
  gather(key = word, value = count, -message_index, -message_label) %>%
  group_by(word) %>%
  summarize(occurence = sum(count)) %>%
  arrange(desc(occurence)) %>%
  slice(1:10)

#Split the data

set.seed(1234)

sample_set <- sample(nrow(email), round(nrow(email) * .75), replace = FALSE)
email_train <- email[sample_set,]
email_test <- email[-sample_set,]

#Check the class distributions

round(prop.table(table(select(email, message_label))), 2)
round(prop.table(table(select(email_train, message_label))), 2)
round(prop.table(table(select(email_test, message_label))), 2)

#Create a model

library(e1071)

email_mod <- naiveBayes(message_label ~ . -message_index, data = email_train, laplace = 1)

#Finding the predicted probabilities for each email being ham or spam

email_pred <- predict(email_mod, email_test, type = "raw")
head(email_pred)

#Finding the predicted labels for each email being ham or spam

email_pred <- predict(email_mod, email_test, type = "class")
head(email_pred)

#Create a confusion matrix to evaluate the accuracy of the model

email_pred_table <- table(email_test$message_label, email_pred)

email_pred_table

sum(diag(email_pred_table)) / nrow(email_test)

#CASE STUDY: REVISITING THE HEART DISEASE DETECTION PROBLEM

#Importing data set

heart <- read_csv(file = "C:/Users/daily/Desktop/Repositories/Practical-Machine-Learning-in-R/Chapter 7/Data/heart.csv", col_types = "nffnnffnfnfnff")

#View the data

glimpse(heart)

#Summarize the data

summary(heart)

#Split the data

set.seed(1234)

sample_set <- sample(nrow(heart), round(nrow(heart) * .75), replace = FALSE)
heart_train <- heart[sample_set,]
heart_test <- heart[-sample_set,]

#Check the class distributions

round(prop.table(table(select(heart, heartDisease))), 2)
round(prop.table(table(select(heart_train, heartDisease))), 2)
round(prop.table(table(select(heart_test, heartDisease))), 2)

#Create a model

heart_mod <- naiveBayes(heartDisease ~ ., data = heart_train, laplace = 1)

#View the probabilities generated by the model

heart_mod

#Finding the predicted labels for each email being ham or spam

heart_pred <- predict(heart_mod, heart_test, type = "class")

#Create a confusion matrix to evaluate the accuracy of the model

heart_pred_table <- table(heart_test$heartDisease, heart_pred)

heart_pred_table

sum(diag(heart_pred_table)) / nrow(heart_test)
